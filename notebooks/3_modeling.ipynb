{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f741bd48",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Build, train and tune ML models to predict heart disease using preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88641f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libaries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the saved data splits\n",
    "with open(\"split_data/x_train.pkl\", \"rb\") as f:\n",
    "    x_train = pickle.load(f)\n",
    "\n",
    "with open(\"split_data/y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(\"split_data/x_test.pkl\", \"rb\") as f:\n",
    "    x_test = pickle.load(f)\n",
    "\n",
    "with open(\"split_data/y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a78df2",
   "metadata": {},
   "source": [
    "## Dealing with Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb827c",
   "metadata": {},
   "source": [
    "Note that the dataset is imbalanced, where most entries belong to the \"Absent\" class for heart disease status. It is important to deal with this imbalance as it may cause the model to be bias and predict the majority class more. Oversampling to balance the classes in the training set will allow the model to better learn patterns associated with the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbcd46a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced training set distribution:\n",
      "heart_disease_status\n",
      "Absent     6400\n",
      "Present    6400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine x_train and y_train for oversampling\n",
    "training_data = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "# Oversampling (for equal majority and minority class)\n",
    "majority_class = training_data[training_data[\"heart_disease_status\"] == \"Absent\"]\n",
    "minority_class = training_data[training_data[\"heart_disease_status\"] == \"Present\"]\n",
    "minority_oversampled = minority_class.sample(n = len(majority_class), replace = True, random_state = 1)\n",
    "\n",
    "# New training data\n",
    "training_data_balanced = pd.concat([majority_class, minority_oversampled])\n",
    "training_data_balanced = training_data_balanced.sample(frac = 1, random_state = 1).reset_index(drop = True)\n",
    "\n",
    "# Separate balanced training data\n",
    "x_train_balanced = training_data_balanced.drop(columns = [\"heart_disease_status\"])\n",
    "y_train_balanced = training_data_balanced[\"heart_disease_status\"]\n",
    "\n",
    "# After oversampling\n",
    "print(\"Balanced training set distribution:\")\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc57ee",
   "metadata": {},
   "source": [
    "## Training and Comparing Models\n",
    "Cross-validation will be used to compare each model and evaluate their performances on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe9962",
   "metadata": {},
   "source": [
    "A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5608e49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Accuracy: 0.5084\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, random_state=1))\n",
    "])\n",
    "\n",
    "scores_lr = cross_val_score(pipe_lr, x_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Logistic Regression CV Accuracy: {scores_lr.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a69f39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    (\"model\", RandomForestClassifier(random_state=1))\n",
    "])\n",
    "\n",
    "scores_rf = cross_val_score(pipe_rf, x_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Random Forest CV Accuracy: {scores_rf.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45cf869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Accuracy: 0.7039\n"
     ]
    }
   ],
   "source": [
    "pipe_svc = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", SVC(probability=True, random_state=1))\n",
    "])\n",
    "\n",
    "scores_svc = cross_val_score(pipe_svc, x_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
    "print(f\"SVM CV Accuracy: {scores_svc.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abbf109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CV Accuracy: 0.6945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "scores_knn = cross_val_score(pipe_knn, x_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
    "print(f\"KNN CV Accuracy: {scores_knn.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53ed0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM CV Accuracy: 0.8212\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=1, verbose=-1)\n",
    "scores_lgbm = cross_val_score(lgbm, x_train_balanced, y_train_balanced, cv=5, scoring=\"accuracy\")\n",
    "print(f\"LightGBM CV Accuracy: {scores_lgbm.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d857dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marku\\OneDrive\\Documents\\Vscode Coding\\Life-Expectancy-Project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:29:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\marku\\OneDrive\\Documents\\Vscode Coding\\Life-Expectancy-Project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\marku\\OneDrive\\Documents\\Vscode Coding\\Life-Expectancy-Project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\marku\\OneDrive\\Documents\\Vscode Coding\\Life-Expectancy-Project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\marku\\OneDrive\\Documents\\Vscode Coding\\Life-Expectancy-Project\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV Accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "# Create a one-hot encoded version of X\n",
    "import pandas as pd\n",
    "\n",
    "x_encoded = pd.get_dummies(x_train_balanced, drop_first=True)\n",
    "\n",
    "# Encode target without changing original\n",
    "y_temp = y_train_balanced.map({\"Absent\": 0, \"Present\": 1})\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=1)\n",
    "\n",
    "scores = cross_val_score(xgb, x_encoded, y_temp, cv=5, scoring=\"accuracy\")\n",
    "print(f\"XGBoost CV Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc2adf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38a4ca03",
   "metadata": {},
   "source": [
    "âœ… 1. Modeling Notebook\n",
    "Purpose: Build, train, and tune machine learning models.\n",
    "\n",
    "What to include:\n",
    "\n",
    "Load preprocessed & split data (e.g., from a .pkl file)\n",
    "\n",
    "Oversample training data\n",
    "\n",
    "Train multiple models (e.g., Random Forest, Logistic Regression)\n",
    "\n",
    "Use cross-validation\n",
    "\n",
    "Hyperparameter tuning (GridSearchCV, RandomizedSearchCV)\n",
    "\n",
    "Select the best model based on metrics\n",
    "\n",
    "Make predictions on test data\n",
    "\n",
    "Save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e1f3e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
